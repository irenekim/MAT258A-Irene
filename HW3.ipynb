{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 MAT258A Irene Kim 999477003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-First this is a test script that applies to a simple function(quadratic) that converges at one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Toms566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 1.0\n",
       " 3.0\n",
       " 5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "function ff(x) \n",
    "    (x-3)^2 + 5\n",
    "end\n",
    "function gg(x) \n",
    "    2*(x-3)\n",
    "end\n",
    "H = 2 #here we have positive constant hessian so don't need to alter\n",
    "\n",
    "function test(x0, optTol = 1e-6)\n",
    "    x = x0\n",
    "    f = ff(x)\n",
    "    itn = 0\n",
    "    while abs(gg(x))>optTol*abs(gg(x0))\n",
    "        d = -gg(x)/2\n",
    "        x = x+d\n",
    "        f = [f;ff(x)]\n",
    "        itn = itn+1\n",
    "    end\n",
    "    [itn; x; ff(x)]\n",
    "end\n",
    "\n",
    "test(0, 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try the simple Newton's method to the 18 problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1  32     2.50e+03     4.10e-12\n",
      "  2 500     7.79e-01     6.10e+00\n",
      "  3   2     3.89e-06     1.13e-08\n",
      "  4  15     1.14e+00     2.00e+00\n",
      "  5   7     1.03e+03     4.95e-08\n",
      "  6  17     9.39e+10     5.08e+03\n",
      "  7 500     3.00e+01     3.00e+68\n",
      "  8  11     5.45e+09     4.78e+01\n",
      "  9  68     2.87e+05     8.81e+01\n",
      " 10 500     1.00e+12     1.00e+12\n",
      " 11 500     7.93e+06    3.34e+111\n",
      " 12 500     1.21e+01     1.35e+65\n",
      " 13  12     2.01e-03     2.13e-18\n",
      " 14 500     4.84e+02     1.23e+19\n",
      " 15 500     3.23e+03     4.16e+44\n",
      " 16   1     1.42e+01     1.42e+01\n",
      " 17  11     1.92e+04     7.88e+00\n",
      " 18   8     1.39e-02          NaN\n"
     ]
    }
   ],
   "source": [
    "function NWTNsimple(p::Toms566.Problem, optTol, maxItn)\n",
    "    x = p.x0\n",
    "    f = p.obj(x)\n",
    "    g = p.grd(x)\n",
    "    H = p.hes(x)\n",
    "    itn = 0\n",
    "    \n",
    "    while norm(p.grd(x))> optTol*norm(p.grd(p.x0))\n",
    "        #first compute d ; the descent direction\n",
    "        #we use hessian no matter if it is positive definite or not\n",
    "        d = p.hes(x)\\(-p.grd(x))\n",
    "        x = x + d #newton's method alpha equals 1\n",
    "        f = [f;p.obj(x)]\n",
    "        itn = itn+1\n",
    "        if itn == maxItn\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    [itn; p.obj(p.x0); p.obj(x)]\n",
    "end\n",
    "\n",
    "for i in 1:18\n",
    "    p = Problem(i)\n",
    "    @printf(\"%3i %3i %12.2e %12.2e\\n\", i,NWTNsimple(p, 1e-6, 500)...)\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We see from the result that number 2, 7, 10, 11, 12, 14, 15, 18 does not seem to have converged. Also, since this is a simple Newton's method, we only know that those that converged have found the stationary points, but that we can't guarantee it is a minimizing point. So, now we inclue the modification of the Hessian matrix algorithm where we decompose the Hessian and alter the eigenvalues to be maximum of 1 and the eigenvalues. Also, we include a backtrack linesearch algorithm to find the stepsize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   8     2.50e+03     3.96e-14\n",
      "  2 100     7.79e-01     2.24e-01\n",
      "  3   2     3.89e-06     1.13e-08\n",
      "  4  91     1.14e+00     2.07e-14\n",
      "  5  13     1.03e+03     8.20e-09\n",
      "  6   7     9.39e+10     1.17e+03\n",
      "  7 100     3.00e+01     3.27e-02\n",
      "  8  11     5.45e+09     4.78e+01\n",
      "  9  18     2.87e+05     8.81e+01\n",
      " 10   7     1.00e+12     3.16e-30\n",
      " 11 100     7.93e+06     1.43e+06\n",
      " 12 100     1.21e+01     3.88e+00\n",
      " 13 100     2.01e-03     6.49e-06\n",
      " 14 100     4.84e+02     1.81e+02\n",
      " 15 100     3.23e+03     5.84e+01\n",
      " 16   9     1.42e+01     1.06e-17\n",
      " 17   8     1.92e+04     7.88e+00\n",
      " 18 100     1.39e-02     7.60e-03\n"
     ]
    }
   ],
   "source": [
    "#Modified Newton's(modifying the Hessian matrix) method with backtracking\n",
    "function NWTNmod2bt(p::Toms566.Problem, optTol, eps, maxItn)\n",
    "    x = p.x0\n",
    "    f = p.obj(x)\n",
    "    g = p.grd(x)\n",
    "    itn = 0\n",
    "    while norm(p.grd(x))>optTol*norm(p.grd(p.x0))\n",
    "        #first compute d ; the descent direction\n",
    "        #first we check if the hessian is positive definite\n",
    "        if minimum(eig(p.hes(x))[1])<=0\n",
    "            D, V = eig(p.hes(x))\n",
    "            y = map(x->max(x,eps), D)\n",
    "            H = V*Diagonal(y)*V'\n",
    "            #eye(size(p.hes(x))[1], size(p.hes(x))[2])\n",
    "        else \n",
    "            H = p.hes(x)\n",
    "        end\n",
    "        #now H is positive definite\n",
    "        d = H\\(-p.grd(x))\n",
    "        #will do backtrack on alpha\n",
    "        alpha = 1\n",
    "        while p.obj(x+alpha*d)>p.obj(x) + alpha*0.4*dot(d,p.grd(x))\n",
    "                alpha = alpha/2\n",
    "            end\n",
    "        x = x + alpha*d\n",
    "        itn = itn+1\n",
    "        if itn == maxItn \n",
    "            break \n",
    "        end\n",
    "    end\n",
    "    [itn; p.obj(p.x0); p.obj(x)]\n",
    "end\n",
    "\n",
    "for i in 1:18\n",
    "    p = Problem(i)\n",
    "    @printf(\"%3i %3i %12.2e %12.2e\\n\", i, NWTNmod2bt(p, 1e-6, 1, 100)...)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we get # 2, 7, 11-15, 18 not converging in 100 steps. Now we try a different alteration of the hessian matrix to try the remaining problems, by altering the eigenvalues to be maximum of 1 and absolute value of the eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NWTNmod1bt (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function NWTNmod1bt(p::Toms566.Problem, optTol, eps, mu, maxItn)\n",
    "    x = p.x0\n",
    "    f = p.obj(x)\n",
    "    g = p.grd(x)\n",
    "    itn = 0\n",
    "    while norm(p.grd(x))>optTol*norm(p.grd(p.x0))\n",
    "        #first compute d ; the descent direction\n",
    "        #first we check if the hessian is positive definite\n",
    "        if minimum(eig(p.hes(x))[1])<=0\n",
    "            D, V = eig(p.hes(x))\n",
    "            y = map(x->max(abs(x),eps), D)\n",
    "            H = V*Diagonal(y)*V'\n",
    "            #eye(size(p.hes(x))[1], size(p.hes(x))[2])\n",
    "        else \n",
    "            H = p.hes(x)\n",
    "        end\n",
    "        #now H is positive definite\n",
    "        d = H\\(-p.grd(x))\n",
    "        #will do backtrack on alpha\n",
    "        alpha = 1\n",
    "        while p.obj(x+alpha*d)>p.obj(x) + alpha*mu*dot(d,p.grd(x))\n",
    "                alpha = alpha/2\n",
    "            end\n",
    "        x = x + alpha*d\n",
    "        itn = itn+1\n",
    "        if itn == maxItn \n",
    "            break \n",
    "        end\n",
    "    end\n",
    "    [itn; p.obj(p.x0); p.obj(x)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2 100     7.79e-01     2.62e-01\n",
      "  7 100     3.00e+01     2.91e-02\n",
      " 11  18     7.93e+06     8.58e+04\n",
      " 12 100     1.21e+01     3.88e+00\n",
      " 13 100     2.01e-03     6.47e-06\n",
      " 14 100     4.84e+02     8.17e+01\n",
      " 15 100     3.23e+03     3.76e-01\n",
      " 18 100     1.39e-02     7.45e-03\n"
     ]
    }
   ],
   "source": [
    "for i in [2;7;11:15;18]\n",
    "    p = Problem(i)\n",
    "    @printf(\"%3i %3i %12.2e %12.2e\\n\", i, NWTNmod1bt(p, 1e-6, 1, 1e-4, 100)...)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that # 11 converged. Hence now the remaining problems are # 2, 7, 12, 13, 14, 15, 18. Now, we'll try the quasi-Newton BFGS method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1  27     2.50e+03     1.30e-16\n",
      "  2 111     7.79e-01     8.04e-16\n",
      "  3   4     3.89e-06     1.13e-08\n",
      "  4 157     1.14e+00     2.97e-18\n",
      "  5 1000     1.03e+03     4.62e-03\n",
      "  6 523     9.39e+10     1.57e+05\n",
      "  7  95     3.00e+01     1.40e-06\n",
      "  8  51     5.45e+09     4.90e-02\n",
      "  9 1000     2.87e+05     8.81e+01\n",
      " 10  38     1.00e+12     9.09e-19\n",
      " 11  21     7.93e+06     8.58e+04\n",
      " 12  33     1.21e+01     2.34e-15\n",
      " 13  64     2.01e-03     3.95e-06\n",
      " 14 234     4.84e+02     4.27e-11\n",
      " 15 262     3.23e+03     1.31e-08\n",
      " 16  13     1.42e+01     8.34e-17\n",
      " 17 1000     1.92e+04     7.87e+00\n",
      " 18 336     1.39e-02     5.39e-03\n"
     ]
    }
   ],
   "source": [
    "#Quasi Newton method\n",
    "function NWTNquasi(p::Toms566.Problem, optTol, maxItn)\n",
    "    itn = 0\n",
    "    x = p.x0\n",
    "    D, V = eig(p.hes(p.x0))\n",
    "    y = map(x->max(x,1), D)\n",
    "    H = V*Diagonal(1./y)*V'#inversion of modified hessian matrix\n",
    "    while norm(p.grd(x))>optTol*norm(p.grd(p.x0))\n",
    "        #first compute d ; the descent direction\n",
    "        #first we check if the hessian is positive definite\n",
    "        d = H*(-p.grd(x))\n",
    "        \n",
    "    #finding alpha satifying Wolfe’s condition\n",
    "        alpha = 1\n",
    "        while p.obj(x+alpha*d)>p.obj(x) + alpha*1e-3*dot(d,p.grd(x))\n",
    "            alpha = alpha*(1/2)\n",
    "            if alpha <= 1e-6\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        while dot(d,p.grd(x+alpha*d))<dot(0.9*d,p.grd(x))\n",
    "            alpha = alpha*(1/2)\n",
    "            if alpha <= 1e-6\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "\n",
    "        x = x+alpha*d\n",
    "        s = alpha*d\n",
    "        y = p.grd(x)-p.grd(x-s)\n",
    "        ro = 1/dot(y,s)\n",
    "        H = (eye(H)-ro*s*y')*H*(eye(H)-ro*y*s') + ro*s*s'\n",
    "        itn = itn + 1\n",
    "        if itn == maxItn \n",
    "            break \n",
    "        end\n",
    "    end\n",
    "    [itn; p.obj(p.x0); p.obj(x)]\n",
    "end\n",
    "\n",
    "for i in 1:18\n",
    "    p = Problem(i)\n",
    "    @printf(\"%3i %3i %12.2e %12.2e\\n\", i,NWTNquasi(p, 1e-8, 1000)...)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in the result that the problems # 2, 7, 12-15, 18 all now have converged with alteration of the optTol value(smaller) and more steps.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hf (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Admissions = readdlm(\"/Users/Irene/Documents/UCD/2015fall/MAT258a/hw2/binary.csv\", ',', header=true);\n",
    "\n",
    "y = Admissions[1][1:400,1];#response variable 400x1\n",
    "u0 = Admissions[1][1:400,2:3]*float(Diagonal([1/400, 1]));#GRE and GPA\n",
    "u = (cat(2,[1 for i = 1:400],u0))';#the vector(data) that we do inner product to the parameters beta and a 400x3\n",
    "\n",
    "#define the objective, gradient and hessian functions\n",
    "#objective function\n",
    "function f(x)#x is the parameter values and f is the negative log likelihood \n",
    "    obj = 0\n",
    "    for i = 1:400\n",
    "        obj = obj - y[i,]*(x'*u[:,i]) + log(1+exp(x'*u[:,i]))\n",
    "    end\n",
    "    obj\n",
    "end\n",
    "\n",
    "function gf(x)#compute the graident\n",
    "    g = [0;0;0]\n",
    "    for i = 1:400\n",
    "        g = g - vec(y[i,].*u[:,i] - ( (exp(x'*u[:,i])) / (1+exp(x'*u[:,i])) ).*u[:,i])  \n",
    "    end\n",
    "    g\n",
    "end\n",
    "\n",
    "function hf(x)#compute the hessian\n",
    "    h = 0\n",
    "    for i = 1:400\n",
    "        h = h + (exp(x'*u[:,i]))/(1 + exp(x'*u[:,i])).*u[:,i]*u[:,i]'\n",
    "    end\n",
    "    h\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NWTN (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modified newton's method(hessian alteration) with backtracking alpha\n",
    "function NWTN(x0, optTol, eps, mu, maxItn)\n",
    "    x = x0\n",
    "    itn = 0\n",
    "    for itn = 1:maxItn\n",
    "        \n",
    "        if norm(gf(x))<=optTol*norm(gf(x0))\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        #to decide the step direction, first alter hessian as needed\n",
    "        D, V = eig(hf(x))\n",
    "\n",
    "        if minimum(D)<=0\n",
    "            pD = map(x->max(x,eps), D)\n",
    "            h = V*pD*V'\n",
    "        else\n",
    "            h = hf(x)\n",
    "        end\n",
    "\n",
    "        d = -h\\gf(x)#we found the descending direction!\n",
    "        #now we need to choose alpha\n",
    "        alpha = 1\n",
    "        while ( f(x+alpha*d) - f(x) + alpha*mu*(d'*gf(x)) )[]>0\n",
    "            alpha = (1/2)*alpha\n",
    "            if alpha<1e-7\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        x = x+alpha*d\n",
    "        itn = itn + 1 \n",
    "    end\n",
    "    [itn;x;f(x)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       "  16.0     \n",
       "  -4.94938 \n",
       "   1.07627 \n",
       "   0.754688\n",
       " 240.172   "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = [0;0;0]\n",
    "NWTN(x0, 1e-6, 1, 0.2, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that there were 16 iterations to convergence where in the last homework with 1st order method there were 20+ iterations needed for convergence. We see that second order method performs better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.0",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
